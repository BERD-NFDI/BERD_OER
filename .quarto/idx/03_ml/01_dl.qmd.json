{"title":"Deep Learning","markdown":{"yaml":{"title":"Deep Learning"},"headingText":"Introduction","headingAttr":{"id":"Introduction-DL","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n<!-- TODO: add a section on Tasks -->\n\nDeep learning (DL) is a specialised subfield of machine learning that employs neural networks to represent and approximate complex, non-linear relationships in data. DL methods have achieved leading empirical performance on a range of tasks, including pattern recognition, natural language processing, and data generation, and have contributed substantially to recent methodological advances.\n\n\nAn introductory course on deep learning is offered by Stanford University and encompasses an introduction to the fundamentals of deep learning, as well as examples of more sophisticated topics, including deep reinforcement learning.\n\n- [Deep Learning - Stanford CS231N - YouTube Playlist](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLSVEhWrZWDHQTBmWZufjxpw3s8sveJtnJ&index=1)\n\n::: {.callout-note icon=false}\n## Further Keywords\nconvolutional neural networks (CNN), image classification, loss functions, optimization, training, software, recurrent neural networks (RNN), detection and segmentation, computer vision, generative models, hardware, adverserial training \n:::\n\n```{r tag_IntroDL, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Intro-DL\")\n```\n\nAnother introductory course is offered by TUM, providing an overview of deep learning along with a detailed look at model training, optimization methods, and the use of non-linear layers in neural networks.\n\n- [Introduction to Deep Learning (I2DL) - Slides](https://www.3dunderstanding.org/i2dl-w22/)\n\n::: {.callout-note icon=false}\n## Further Keywords\nML basics, linear regression, maximum likelihood, neural networks, computational graphs, optimization, backpropagation, scaling optimization, stochastic gradient descent (SGD), training, CNNs, RNN, transformers, advanced DL \n:::\n\n```{r tag_IntroDLTUM, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Intro-DL-TUM\")\n```\n\n#### Methods {#Methods-DL}  \n\nDeep learning methods are built around the concept of artificial neural networks, which are trained using optimization techniques such as gradient descent. Core components include **loss functions**, which measure the difference between predictions and intended outcomes, and **optimization** algorithms, such as stochastic gradient descent (SGD) and Adam, which update network parameters. **Regularization** techniques, including dropout and weight decay, help prevent overfitting, while **training strategies**, such as batch normalization and learning rate schedules, support more efficient and robust learning.\n\nHyperparameter tuning is an essential part of training deep learning models efficiently. For practical guidance, see:\n\n- [Tune: Scalable Hyperparameter Tuning - Slides](https://docs.ray.io/en/latest/tune/index.html)\n- [Tune: Scalable Hyperparameter Tuning - Code Examples](https://optuna.org/#code_examples)\n\n::: {.callout-note icon=false}\n## Further Keywords\nray tune, search space, search algorithm, scheduler, tuner, trials, function API, class API, random search, grid search, Bayesian optimization, Bandit optimization, tree-parzen estimators, gradient-free optimization, optuna search algorithms, median stopping rule, ASHA, Population Based Training (PBT) \n:::\n\n```{r tag_Hyperparam, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Hyperparam\")\n```\n\nUnderstanding and applying effective training strategies, including learning rate schedules and batch normalization, is crucial for model performance. For hands-on examples using PyTorch, see:\n\n- [Guide to Pytorch Learning Rate Scheduling](https://www.kaggle.com/code/isbhargav/guide-to-pytorch-learning-rate-scheduling)\n\n::: {.callout-note icon=false}\n## Further Keywords\nlambda, multiplicative, step, MultiStep, exponential, cosine annealing, cyclic, OneCycle, cosine annealing with warm restarts\n:::\n\n```{r tag_PyTorchLearningRate, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"PyTorchLearningRate\")\n```\n\nFor a broader overview of deep learning in Python, including an introduction to PyTorch with tutorials and practical exercises, see the [Deep Learning with Python](../04_code/03_python.qmd#DLwithPython) coding section.\n\n#### Architectures {#Architectures-DL}\n\nDeep learning architectures define how neural networks are structured to process different types of data. **Convolutional Neural Networks (CNNs)** are specialized for spatial data such as images, while **Recurrent Neural Networks (RNNs)** handle sequential data, including text and time series. **Transformers** use self-attention mechanisms to model long-range dependencies in sequences and represent the current state-of-the-art for many NLP and sequence tasks. **Autoencoders** are unsupervised models commonly used for dimensionality reduction, learning meaningful representations, and detecting anomalies. \n\nThis application provides a technical demo of a CNN using the MNIST dataset, a widely used benchmark of handwritten digits. Users can draw their own digits and observe how the network processes them. The source code and related publication are also available:\n\n- [An Interactive Node-Link Visualization of Convolutional Neural Networks](https://adamharley.com/nn_vis/)\n\n::: {.callout-note icon=false}\n## Further Keywords\nCNN, MNIST, visualization, filters, feature maps, 3D fully-connected network, 2D, nodes, bottom layer, hidden layer, output layer, convolutional layer, flattening \n:::\n\n```{r tag_VisualCNN, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"VisualCNN\")\n```\n\nThe following lecture-style video covers the Transformer architecture and its applications and is best for those familiar with neural networks and embeddings.\n\n- [Introduction to the Transformer Architecture - YouTube Video](https://www.youtube.com/watch?v=EixI6t5oif0)\n\n::: {.callout-note icon=false}\n## Further Keywords\ncomputer vision, NLP, reinforcement learning, speech, translation, graphs, attention, tokenization, embeddings, positional encoding, multi-headed self-attention, point-wise MLP, GeLU, layer normalization, encoder, decoder, masked self-attention, generation, cross attention, feedforward, compute budget heuristics, ExaFLOPs, GPU, mixture of experts, ViT, convolution-augmented transformer, decision transformer\n:::\n\n```{r tag_Intro-Transformer, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Intro-Transformer\")\n```\n\nMore on Transformers can be found in the [NLP](02_nlp.qmd#LLMs) chapter.\n\n#### Model Classes {#ModelClasses-DL}\n\nBeyond general architectures, deep learning includes several specialized model classes that address specific goals. **Generative Adversarial Networks (GANs)** learn to generate new data by creating a competition between a generator and a discriminator. **Variational Autoencoders (VAEs)** extend standard autoencoders probabilistically, modeling a latent variable distribution and optimizing a variational lower bound to enable generative modeling. Recently, **diffusion models** have gained popularity as generative models that iteratively refine noisy data into structured outputs.\n\nFor a deeper dive into diffusion models, see:  \n\n- [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n\n::: {.callout-note icon=false}\n## Further Keywords\nMarkov chain, random noise, latent variable, Gaussian noise, forward process, Langevin dynamics, reverse process, Bayes' rule, parametrization, training loss, noise-conditioned score networks (NCSN), classifier guided diffusion, classifier-free guidance, sampling steps, progressive distillation, DDPM, DDIM, consistency models, latent variable space, CLIP, U-Net, Transformer, ControlNet\n:::\n\n```{r tag_Diffusion, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Diffusion\")\n```\n\nLaplace Redux provides a practical library for applying Laplace approximations in neural networks, whether for entire networks, subnetworks, or just the last layer. The package enables posterior approximations, marginal-likelihood estimation, and posterior predictive computations, and includes multiple example scenarios. Implementing Laplace approximations from scratch is difficult due to the Hessian computations, so this library offers a straightforward way to experiment with these techniques in code.\n\n- [Laplace Redux - Effortless Bayesian Deep Learning](https://aleximmer.github.io/Laplace/)\n\n::: {.callout-note icon=false}\n## Further Keywords\ntorch, marginal likelihood, laplace on LLMs, serialization, backend, regression, calibration, GP inference, huggingface LLMs, reward modeling, API\n:::\n\n```{r tag_LaplaceRedux, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"LaplaceRedux\")\n```","srcMarkdownNoYaml":"\n\n<!-- TODO: add a section on Tasks -->\n\nDeep learning (DL) is a specialised subfield of machine learning that employs neural networks to represent and approximate complex, non-linear relationships in data. DL methods have achieved leading empirical performance on a range of tasks, including pattern recognition, natural language processing, and data generation, and have contributed substantially to recent methodological advances.\n\n#### Introduction {#Introduction-DL}\n\nAn introductory course on deep learning is offered by Stanford University and encompasses an introduction to the fundamentals of deep learning, as well as examples of more sophisticated topics, including deep reinforcement learning.\n\n- [Deep Learning - Stanford CS231N - YouTube Playlist](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLSVEhWrZWDHQTBmWZufjxpw3s8sveJtnJ&index=1)\n\n::: {.callout-note icon=false}\n## Further Keywords\nconvolutional neural networks (CNN), image classification, loss functions, optimization, training, software, recurrent neural networks (RNN), detection and segmentation, computer vision, generative models, hardware, adverserial training \n:::\n\n```{r tag_IntroDL, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Intro-DL\")\n```\n\nAnother introductory course is offered by TUM, providing an overview of deep learning along with a detailed look at model training, optimization methods, and the use of non-linear layers in neural networks.\n\n- [Introduction to Deep Learning (I2DL) - Slides](https://www.3dunderstanding.org/i2dl-w22/)\n\n::: {.callout-note icon=false}\n## Further Keywords\nML basics, linear regression, maximum likelihood, neural networks, computational graphs, optimization, backpropagation, scaling optimization, stochastic gradient descent (SGD), training, CNNs, RNN, transformers, advanced DL \n:::\n\n```{r tag_IntroDLTUM, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Intro-DL-TUM\")\n```\n\n#### Methods {#Methods-DL}  \n\nDeep learning methods are built around the concept of artificial neural networks, which are trained using optimization techniques such as gradient descent. Core components include **loss functions**, which measure the difference between predictions and intended outcomes, and **optimization** algorithms, such as stochastic gradient descent (SGD) and Adam, which update network parameters. **Regularization** techniques, including dropout and weight decay, help prevent overfitting, while **training strategies**, such as batch normalization and learning rate schedules, support more efficient and robust learning.\n\nHyperparameter tuning is an essential part of training deep learning models efficiently. For practical guidance, see:\n\n- [Tune: Scalable Hyperparameter Tuning - Slides](https://docs.ray.io/en/latest/tune/index.html)\n- [Tune: Scalable Hyperparameter Tuning - Code Examples](https://optuna.org/#code_examples)\n\n::: {.callout-note icon=false}\n## Further Keywords\nray tune, search space, search algorithm, scheduler, tuner, trials, function API, class API, random search, grid search, Bayesian optimization, Bandit optimization, tree-parzen estimators, gradient-free optimization, optuna search algorithms, median stopping rule, ASHA, Population Based Training (PBT) \n:::\n\n```{r tag_Hyperparam, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Hyperparam\")\n```\n\nUnderstanding and applying effective training strategies, including learning rate schedules and batch normalization, is crucial for model performance. For hands-on examples using PyTorch, see:\n\n- [Guide to Pytorch Learning Rate Scheduling](https://www.kaggle.com/code/isbhargav/guide-to-pytorch-learning-rate-scheduling)\n\n::: {.callout-note icon=false}\n## Further Keywords\nlambda, multiplicative, step, MultiStep, exponential, cosine annealing, cyclic, OneCycle, cosine annealing with warm restarts\n:::\n\n```{r tag_PyTorchLearningRate, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"PyTorchLearningRate\")\n```\n\nFor a broader overview of deep learning in Python, including an introduction to PyTorch with tutorials and practical exercises, see the [Deep Learning with Python](../04_code/03_python.qmd#DLwithPython) coding section.\n\n#### Architectures {#Architectures-DL}\n\nDeep learning architectures define how neural networks are structured to process different types of data. **Convolutional Neural Networks (CNNs)** are specialized for spatial data such as images, while **Recurrent Neural Networks (RNNs)** handle sequential data, including text and time series. **Transformers** use self-attention mechanisms to model long-range dependencies in sequences and represent the current state-of-the-art for many NLP and sequence tasks. **Autoencoders** are unsupervised models commonly used for dimensionality reduction, learning meaningful representations, and detecting anomalies. \n\nThis application provides a technical demo of a CNN using the MNIST dataset, a widely used benchmark of handwritten digits. Users can draw their own digits and observe how the network processes them. The source code and related publication are also available:\n\n- [An Interactive Node-Link Visualization of Convolutional Neural Networks](https://adamharley.com/nn_vis/)\n\n::: {.callout-note icon=false}\n## Further Keywords\nCNN, MNIST, visualization, filters, feature maps, 3D fully-connected network, 2D, nodes, bottom layer, hidden layer, output layer, convolutional layer, flattening \n:::\n\n```{r tag_VisualCNN, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"VisualCNN\")\n```\n\nThe following lecture-style video covers the Transformer architecture and its applications and is best for those familiar with neural networks and embeddings.\n\n- [Introduction to the Transformer Architecture - YouTube Video](https://www.youtube.com/watch?v=EixI6t5oif0)\n\n::: {.callout-note icon=false}\n## Further Keywords\ncomputer vision, NLP, reinforcement learning, speech, translation, graphs, attention, tokenization, embeddings, positional encoding, multi-headed self-attention, point-wise MLP, GeLU, layer normalization, encoder, decoder, masked self-attention, generation, cross attention, feedforward, compute budget heuristics, ExaFLOPs, GPU, mixture of experts, ViT, convolution-augmented transformer, decision transformer\n:::\n\n```{r tag_Intro-Transformer, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Intro-Transformer\")\n```\n\nMore on Transformers can be found in the [NLP](02_nlp.qmd#LLMs) chapter.\n\n#### Model Classes {#ModelClasses-DL}\n\nBeyond general architectures, deep learning includes several specialized model classes that address specific goals. **Generative Adversarial Networks (GANs)** learn to generate new data by creating a competition between a generator and a discriminator. **Variational Autoencoders (VAEs)** extend standard autoencoders probabilistically, modeling a latent variable distribution and optimizing a variational lower bound to enable generative modeling. Recently, **diffusion models** have gained popularity as generative models that iteratively refine noisy data into structured outputs.\n\nFor a deeper dive into diffusion models, see:  \n\n- [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n\n::: {.callout-note icon=false}\n## Further Keywords\nMarkov chain, random noise, latent variable, Gaussian noise, forward process, Langevin dynamics, reverse process, Bayes' rule, parametrization, training loss, noise-conditioned score networks (NCSN), classifier guided diffusion, classifier-free guidance, sampling steps, progressive distillation, DDPM, DDIM, consistency models, latent variable space, CLIP, U-Net, Transformer, ControlNet\n:::\n\n```{r tag_Diffusion, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Diffusion\")\n```\n\nLaplace Redux provides a practical library for applying Laplace approximations in neural networks, whether for entire networks, subnetworks, or just the last layer. The package enables posterior approximations, marginal-likelihood estimation, and posterior predictive computations, and includes multiple example scenarios. Implementing Laplace approximations from scratch is difficult due to the Hessian computations, so this library offers a straightforward way to experiment with these techniques in code.\n\n- [Laplace Redux - Effortless Bayesian Deep Learning](https://aleximmer.github.io/Laplace/)\n\n::: {.callout-note icon=false}\n## Further Keywords\ntorch, marginal likelihood, laplace on LLMs, serialization, backend, regression, calibration, GP inference, huggingface LLMs, reward modeling, API\n:::\n\n```{r tag_LaplaceRedux, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"LaplaceRedux\")\n```"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"toc-depth":4,"include-after-body":["../_footer.html"],"output-file":"01_dl.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","theme":"cosmo","toc-location":"left","title":"Deep Learning"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}