{"title":"Trustworthy Machine Learning","markdown":{"yaml":{"title":"Trustworthy Machine Learning"},"headingText":"Uncertainty Quantification","headingAttr":{"id":"UQ","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\nAs machine learning systems are increasingly used to inform decisions in science, business, and society, trustworthiness becomes a central concern. A trustworthy model is not only accurate but also reliable, transparent, and fair - it provides predictions that users can understand and act upon with confidence. Building such systems involves assessing their **uncertainty**, improving their **explainability**, and ensuring their **interpretability**. These aspects help identify when to trust a model’s output, when to question it, and how to make machine learning a responsible tool for real-world applications.\n\n**Uncertainty Quantification (UQ)** involves techniques to measure and express the uncertainty in model predictions. This is crucial in high-stakes applications where decisions based on model outputs can have significant consequences. One key aspect of UQ is distinguishing between different kinds of uncertainty, such as aleatoric and epistemic, which helps practitioners make more informed decisions. More information on this distinction can be found below:\n\n- [Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods - Presentation](https://www.gdsd.statistik.uni-muenchen.de/2021/gdsd_huellermeier.pdf)\n- [Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods - Paper](https://link.springer.com/article/10.1007/s10994-021-05946-3)\n\n::: {.callout-note icon=false}\n## Further Keywords\nsupervised learning, predictive uncertainty, induction principle, learning algorithm, probabilistic predictors, training data, hypothesis space, empirical risk, risk minimizer, sources of uncertainty, Bayes predictor, reducible vs irreducible, ensemble learning, Bayesian agents, mutual information \n:::\n\n```{r tag_UQ, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"UQ\")\n```\n\n\n### Explainability {#XAI}\n\n**Explainable Artificial Intelligence (XAI)** focuses on developing methods that make the behavior of machine learning models understandable to humans. This is particularly important for complex models like deep neural networks, which are often seen as \"black boxes.\" XAI techniques aim to provide insights into how models make decisions, which features are most influential, and how changes in input data affect outputs. This transparency is essential for building trust, ensuring accountability, and facilitating regulatory compliance in AI applications.\n\n- [Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI](https://arxiv.org/abs/1910.10045)\n\n::: {.callout-note icon=false}\n## Further Keywords\npost-hoc explanations, feature importance, saliency maps, decision rules, local vs. global explanations, model transparency\n:::\n\n```{r tag_XAI, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"XAI\")\n```","srcMarkdownNoYaml":"\n\nAs machine learning systems are increasingly used to inform decisions in science, business, and society, trustworthiness becomes a central concern. A trustworthy model is not only accurate but also reliable, transparent, and fair - it provides predictions that users can understand and act upon with confidence. Building such systems involves assessing their **uncertainty**, improving their **explainability**, and ensuring their **interpretability**. These aspects help identify when to trust a model’s output, when to question it, and how to make machine learning a responsible tool for real-world applications.\n\n### Uncertainty Quantification {#UQ}\n**Uncertainty Quantification (UQ)** involves techniques to measure and express the uncertainty in model predictions. This is crucial in high-stakes applications where decisions based on model outputs can have significant consequences. One key aspect of UQ is distinguishing between different kinds of uncertainty, such as aleatoric and epistemic, which helps practitioners make more informed decisions. More information on this distinction can be found below:\n\n- [Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods - Presentation](https://www.gdsd.statistik.uni-muenchen.de/2021/gdsd_huellermeier.pdf)\n- [Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods - Paper](https://link.springer.com/article/10.1007/s10994-021-05946-3)\n\n::: {.callout-note icon=false}\n## Further Keywords\nsupervised learning, predictive uncertainty, induction principle, learning algorithm, probabilistic predictors, training data, hypothesis space, empirical risk, risk minimizer, sources of uncertainty, Bayes predictor, reducible vs irreducible, ensemble learning, Bayesian agents, mutual information \n:::\n\n```{r tag_UQ, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"UQ\")\n```\n\n\n### Explainability {#XAI}\n\n**Explainable Artificial Intelligence (XAI)** focuses on developing methods that make the behavior of machine learning models understandable to humans. This is particularly important for complex models like deep neural networks, which are often seen as \"black boxes.\" XAI techniques aim to provide insights into how models make decisions, which features are most influential, and how changes in input data affect outputs. This transparency is essential for building trust, ensuring accountability, and facilitating regulatory compliance in AI applications.\n\n- [Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI](https://arxiv.org/abs/1910.10045)\n\n::: {.callout-note icon=false}\n## Further Keywords\npost-hoc explanations, feature importance, saliency maps, decision rules, local vs. global explanations, model transparency\n:::\n\n```{r tag_XAI, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"XAI\")\n```"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"toc-depth":4,"include-after-body":["../_footer.html"],"output-file":"03_trustworthy.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","theme":"cosmo","toc-location":"left","title":"Trustworthy Machine Learning"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}