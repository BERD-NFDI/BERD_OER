{"title":"Machine Learning","markdown":{"yaml":{"title":"Machine Learning"},"headingText":"Learning Paradigms","headingAttr":{"id":"Learning-Paradigms","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\nMachine Learning (ML) focuses on developing algorithms and models that allow computers to learn patterns from data and make predictions or decisions without being explicitly programmed. It spans a wide range of techniques, from traditional statistical methods to modern deep learning approaches, and is applied in domains such as natural language processing ([NLP](02_nlp.qmd)) and computer vision (CV). ML enables the extraction of insights from large and complex datasets, supporting data-driven decision-making across disciplines.\n\nMachine learning can be organized into a variety of learning paradigms, which describe different ways in which models interact with data and potential feedback.\n\nIn **Supervised Learning**, the model is trained on a labeled dataset, where traditionally each input data point is associated with a corresponding output label. The goal is to learn a mapping from inputs to outputs, enabling the model to make accurate predictions on new, unseen data. Common supervised learning tasks include classification (e.g., spam detection) and regression (e.g., predicting house prices). For a discussion of the assumption of a single ground truth label in the context of NLP, see the section on [label variation](02_nlp.qmd#Label-Variation).\n\n**Unsupervised Learning** involves training models on unlabeled data, where the goal is to discover underlying patterns, structures, or relationships within the data. Common unsupervised learning tasks include clustering (e.g., customer segmentation) and dimensionality reduction (e.g., principal component analysis).\n\nAn open and free introductory course on (supervised) machine learning can be found on the [I2ML Course Website](https://slds-lmu.github.io/i2ml/) from the [Statistical Learning and Data Science group](https://www.slds.stat.uni-muenchen.de/) at LMU Munich. The course is constructed as self-contained as possible and enables self-study through lecture videos, PDF slides, cheatsheets, quizzes, exercises (with solutions), and notebooks.\n\n- [I2ML - GitHub Course Page](https://slds-lmu.github.io/i2ml/)\n\n::: {.callout-note icon=false}\n## Further Keywords\nclassification, k-NN, trees, random forests, bagging, neural networks, hyperparameter tuning, train-validation-test-split, advanced risk minimization, multiclass classification, information theory, curse of dimensionality, regularization, SVM, boosting, Gaussian Processes, imbalanced learning, multitarget learning, online learning, feature selection, sklearn, mlr3\n:::\n\n```{r tag_IntroML, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Intro-ML\")\n```\n\nIn addition to supervised and unsupervised approaches, **Self-supervised Learning** leverages automatically generated labels from the data itself, allowing models to learn useful representations without requiring costly manual annotation.\n\n- [Self-supervised Learning: Generative or Contrastive - Paper](https://arxiv.org/pdf/2006.08218.pdf)\n\n::: {.callout-note icon=false}\n## Further Keywords\nauto-regressive, flow-based, auto-encoding, hybrid generative, mutual information, adverserial, GAN, data augmentation, pretext task, BYOL, SimCLR, MoCo, graph learning\n:::\n\n```{r tag_SelfSupervised, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Self-Supervised\")\n```\n\n#### Reinforcement Learning {#RL}\n**Reinforcement Learning** is a paradigm where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions, and the goal is to learn a policy that maximizes cumulative rewards over time. Reinforcement learning is commonly used in applications such as game playing (e.g., AlphaGo) and robotics.\n\n- [Reinforcement Learning for Business, Economics, and Social Sciences - GitHub Repository](https://github.com/BERD-NFDI/BERD-Reinforcement-Learning)\n- [Reinforcement Learning for Business, Economics, and Social Sciences - BERD Academy Information & Registration Page](https://www.berd-nfdi.de/berd-academy/reinforcement-learning-2025/)\n\n\n::: {.callout-note icon=false}\n## Further Keywords\nadaptive experimental designs, bandits, multi-armed, exploration vs. exploitation, regret, reward, stylized data structure, greedy policy, epsilon-greedy, upper confidence bound, uncertainty, Thompson sampling, Bayesian learning, inference with batched bandits\n:::\n\n\n```{r tag_RL, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"RL\")\n```\n\n#### Active Learning {#AL}\n**Active Learning (AL)** is a machine learning approach that aims to maximize model performance while minimizing the amount of labeled data required. Instead of labeling an entire dataset upfront, the algorithm iteratively identifies the most informative or uncertain examples and queries an expert for labels. This strategy is especially useful in domains where labeling is expensive, time-consuming, or requires specialized knowledge, such as medical diagnosis or linguistic annotation. By focusing effort on the most valuable data points, active learning can significantly improve efficiency and accelerate model training without sacrificing accuracy.\n\n#### Automated Machine Learning {#AutoML}\n**Automated Machine Learning (AutoML)** refers to the process of automating the end-to-end workflow of applying machine learning to real-world problems. This includes tasks such as data preprocessing, feature selection, model selection, hyperparameter tuning, and model evaluation. The goal of AutoML is to make machine learning more accessible to non-experts and to improve the efficiency and effectiveness of the model development process.\n\n<!-- - [AutoML - Automated Machine Learning - Course Information & Registration Page](https://ki-campus.org/courses/automl-luh2021)\n- [AutoML - Automated Machine Learning](https://ki-campus.org/courses/automl-luh2021)\n\n::: {.callout-note icon=false}\n## Further Keywords\nR, Python, hyperparameter optimization, bayesian optimization, evolutionary algorithms, neural architecture search, multi-fidelity optimization, gradient-based optimization, meta-learning\n:::\n\n```{r tag_AutoML, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"AutoML\")\n``` -->\n\n","srcMarkdownNoYaml":"\n\nMachine Learning (ML) focuses on developing algorithms and models that allow computers to learn patterns from data and make predictions or decisions without being explicitly programmed. It spans a wide range of techniques, from traditional statistical methods to modern deep learning approaches, and is applied in domains such as natural language processing ([NLP](02_nlp.qmd)) and computer vision (CV). ML enables the extraction of insights from large and complex datasets, supporting data-driven decision-making across disciplines.\n\n### Learning Paradigms {#Learning-Paradigms}\nMachine learning can be organized into a variety of learning paradigms, which describe different ways in which models interact with data and potential feedback.\n\nIn **Supervised Learning**, the model is trained on a labeled dataset, where traditionally each input data point is associated with a corresponding output label. The goal is to learn a mapping from inputs to outputs, enabling the model to make accurate predictions on new, unseen data. Common supervised learning tasks include classification (e.g., spam detection) and regression (e.g., predicting house prices). For a discussion of the assumption of a single ground truth label in the context of NLP, see the section on [label variation](02_nlp.qmd#Label-Variation).\n\n**Unsupervised Learning** involves training models on unlabeled data, where the goal is to discover underlying patterns, structures, or relationships within the data. Common unsupervised learning tasks include clustering (e.g., customer segmentation) and dimensionality reduction (e.g., principal component analysis).\n\nAn open and free introductory course on (supervised) machine learning can be found on the [I2ML Course Website](https://slds-lmu.github.io/i2ml/) from the [Statistical Learning and Data Science group](https://www.slds.stat.uni-muenchen.de/) at LMU Munich. The course is constructed as self-contained as possible and enables self-study through lecture videos, PDF slides, cheatsheets, quizzes, exercises (with solutions), and notebooks.\n\n- [I2ML - GitHub Course Page](https://slds-lmu.github.io/i2ml/)\n\n::: {.callout-note icon=false}\n## Further Keywords\nclassification, k-NN, trees, random forests, bagging, neural networks, hyperparameter tuning, train-validation-test-split, advanced risk minimization, multiclass classification, information theory, curse of dimensionality, regularization, SVM, boosting, Gaussian Processes, imbalanced learning, multitarget learning, online learning, feature selection, sklearn, mlr3\n:::\n\n```{r tag_IntroML, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Intro-ML\")\n```\n\nIn addition to supervised and unsupervised approaches, **Self-supervised Learning** leverages automatically generated labels from the data itself, allowing models to learn useful representations without requiring costly manual annotation.\n\n- [Self-supervised Learning: Generative or Contrastive - Paper](https://arxiv.org/pdf/2006.08218.pdf)\n\n::: {.callout-note icon=false}\n## Further Keywords\nauto-regressive, flow-based, auto-encoding, hybrid generative, mutual information, adverserial, GAN, data augmentation, pretext task, BYOL, SimCLR, MoCo, graph learning\n:::\n\n```{r tag_SelfSupervised, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"Self-Supervised\")\n```\n\n#### Reinforcement Learning {#RL}\n**Reinforcement Learning** is a paradigm where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions, and the goal is to learn a policy that maximizes cumulative rewards over time. Reinforcement learning is commonly used in applications such as game playing (e.g., AlphaGo) and robotics.\n\n- [Reinforcement Learning for Business, Economics, and Social Sciences - GitHub Repository](https://github.com/BERD-NFDI/BERD-Reinforcement-Learning)\n- [Reinforcement Learning for Business, Economics, and Social Sciences - BERD Academy Information & Registration Page](https://www.berd-nfdi.de/berd-academy/reinforcement-learning-2025/)\n\n\n::: {.callout-note icon=false}\n## Further Keywords\nadaptive experimental designs, bandits, multi-armed, exploration vs. exploitation, regret, reward, stylized data structure, greedy policy, epsilon-greedy, upper confidence bound, uncertainty, Thompson sampling, Bayesian learning, inference with batched bandits\n:::\n\n\n```{r tag_RL, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"RL\")\n```\n\n#### Active Learning {#AL}\n**Active Learning (AL)** is a machine learning approach that aims to maximize model performance while minimizing the amount of labeled data required. Instead of labeling an entire dataset upfront, the algorithm iteratively identifies the most informative or uncertain examples and queries an expert for labels. This strategy is especially useful in domains where labeling is expensive, time-consuming, or requires specialized knowledge, such as medical diagnosis or linguistic annotation. By focusing effort on the most valuable data points, active learning can significantly improve efficiency and accelerate model training without sacrificing accuracy.\n\n#### Automated Machine Learning {#AutoML}\n**Automated Machine Learning (AutoML)** refers to the process of automating the end-to-end workflow of applying machine learning to real-world problems. This includes tasks such as data preprocessing, feature selection, model selection, hyperparameter tuning, and model evaluation. The goal of AutoML is to make machine learning more accessible to non-experts and to improve the efficiency and effectiveness of the model development process.\n\n<!-- - [AutoML - Automated Machine Learning - Course Information & Registration Page](https://ki-campus.org/courses/automl-luh2021)\n- [AutoML - Automated Machine Learning](https://ki-campus.org/courses/automl-luh2021)\n\n::: {.callout-note icon=false}\n## Further Keywords\nR, Python, hyperparameter optimization, bayesian optimization, evolutionary algorithms, neural architecture search, multi-fidelity optimization, gradient-based optimization, meta-learning\n:::\n\n```{r tag_AutoML, results = 'asis', echo = FALSE, warning = FALSE, message = FALSE}\nsource(\"../utils.R\")\nrender_tags(\"AutoML\")\n``` -->\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"toc-depth":4,"include-after-body":["../_footer.html"],"output-file":"00_ml_intro.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","theme":"cosmo","toc-location":"left","title":"Machine Learning"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}